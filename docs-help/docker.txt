# HAProxy for free LoadBalancer but I do not know if it works with docker
#links for docker gits:

https://github.com/fundamentalsofdocker/labs

#documentations:

https://docs.docker.com/engine/swarm/

https://docs.docker.com/compose/

https://stackoverflow.com/questions/42208442/maven-docker-cache-dependencies

https://docs.docker.com/engine/reference/commandline/push/



#NOTE : the # contains comments the $ contains the actual command line with placeholders between <>

##################link to install docker-machine ###############################

https://docs.docker.com/v17.09/machine/install-machine/#install-machine-directly

################## link to install virtualbox ###################################

https://itsfoss.com/install-virtualbox-ubuntu/

########### unitest docker#######################################################

https://blog.phonito.io/unit-testing-docker-images/

############# minikube or kubernetes ############################################

https://kubernetes.io/docs/tasks/tools/install-minikube/
################## docker info ##################################################
# CE use moby proiect
# cli use REST api to talk to the daemon
# docker-machine is part of the docker toolbox and is the old version no longer supported
# docker-machine use virtualbox which is a vm
# docker use feature from linux kernel called namespaces, some of them are: process, net, mount
# link is deprecated to link one container with another container by it's name
# the default network is bridge and if you don't create a network this will be use by docker
# if you link multiple containers to a use defined network the name of the container the hostname
# docker cli use REST API to talk to the daemon
# docker container ls  is the same as docker ls  but you should use management command not the aliases
# set DOCKER_HIDE_LEGACY_COMMANDS=true to hide lagacy commands but only for help
# an image could be taged multiple
# official repository are managed by docker.inc or their 3-rd parties that they trust
# official repository has info about security vulnerabilities
# comment is done with the # at the begining of the line and not inline comment
# docker plugin install ... this will install by example new drivers for net, see on docker hub the plugin section
# online repository: https://quay.io/
# docker container run -i attach the standard input and -t attach the sudo tty
# docker container stop send signal SIGTERM to the process 1 inside the container, and after timeout of 10 s it will send SIGKILL
# docker container kill send signal SIGKILL but it could send another signal using -s
# CTRL-C will send SIGINT to the docker client which will send the signal to the process 1 from the container
# as the process 1 is still alive the container will not stop
# the shell will not forward interrupts so is better to use CMD [...] which launch the application as process 1 instead a sh
# you should not write into log file inside the container instead you should use stderr and stdout
# docker decide which stderr or stdout to be flush first
# docker container run --volume is in fact bind (mount)
# mount type,src,destination(dst),readonly
# mount and --volume without the name or src become anonymous volume
# docker volume inspect to see where the volume is located
# docker container inspect to see the mount volumes
# docker will delete anonymous volumes if you use --rm on run
# in Dockerfile the VOLUME will create an anonymous volume
# use bind mount like source code or configuration file
# use volume for data persisted into the container
# anonymous volume are use for testing and using volumes-from-container
# COPY will never delete file from the directory only it will override them
# in COPY if you specify the directory it will copy the content of the directory not also the directory
# ADD could download files and deal with tar so use ADD only if you need those features otherwise use COPY
# docker context: .dockerignore the docker will ignore all the files that are specified in .dockeringnore file
# pass environment variable using -e "var=value" or just -e <environment_var_name> to the container or --env-file with the file
# if you specify in env file just the name of the environment variable name without =value
# envsubst could replace variable from a configuration file jfahrer/envsubst
# resolver 127.0.0.11; is available only in user defined network
# if you use bash as starting script use exec to replace the bash as process 1


################## how to install docker ########################################

#install
$ sudo apt-get update
$ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu noble stable"

Now that you have the repository set up, run the following commands to install Docker:
$ sudo apt-get update
$ sudo apt-get install docker-ce

$ sudo systemctl enable docker
$ sudo systemctl start docker

#test the instalation
$ docker run --rm -ti ubuntu:latest /bin/bash

#or you will have the same result
$ sudo dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375

to see underlining host
$ docker run -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh

/ # cat /etc/os-release
PRETTY_NAME="Docker for Mac"

/ # ps | grep dockerd
 1096 root       0:16 /usr/local/bin/dockerd -H unix:///var/run/docker.sock
                          --config-file /run/config/docker/daemon.json
                          --swarm-default-advertise-addr=eth0
                          --userland-proxy-path /usr/bin/vpnkit-expose-port
                          --storage-driver overlay2

/ # exit

#docker daemon configuration is in /etc/docker/daemon.json
#add the user to run without sudo
$sudo groupadd docker
$sudo usermod -aG docker $USER

#docker toolbox and GUI has:
# Docker Machine, Docker Engine, Docker Compose, Docker GUI (Kitematic). Oracle VirtualBox, preconfigured Shell
# Docker machine is used to manage docker hosts
# on windows has docker notary cli to sign containers
# container does not need hypervisor as the VM need because container is just another process


#adding env to the docker container is done using -e <VAR-NAME>=<VAR-VALUE>

#debug so to export a container into a tarball

$ docker export <containerid> -o <fileName>

#Alpine is based on musl standard library and not glibc and have sh instead of bash. However, you can also install glibc and bash in Alpine Linux if you really need it, and this is often done in the case of JVM containers.

#to longin you should install
$ sudo apt install gnome-keyring

#Create a basic local repository
$ git clone https://github.com/spkane/basic-registry --config core.autocrlf=input
$ cp config.yml.sample config.yml
$ cp registry.key.sample registry.key
$ cp registry.crt.sample registry.crt

#Create key using
$ openssl req -x509 -nodes -sha256 -newkey rsa:4096 -keyout registry.key -out registry.crt -days 14 -subj '/CN=127.0.0.1'
#create the user and password
$ docker run --entrypoint htpasswd httpd:2 -Bbn USERNAM_HERE PASSWORD_HERE > PATH_TOVOLUME/htpasswd

$ docker run --entrypoint htpasswd spkane/basic-registry:latest -Bbn ${<username>} ${<password>} > htpasswd

$ docker build -t my-registry .
$ docker run -d -p 5000:5000 --name registry my-registry
$ docker logs registry
$ docker login 127.0.0.1:5000
#to keep images it could be done using -v /tmp/registry-data:/var/lib/registry

#Keep images small
$ docker run -d -p 8080:8080 adejonge/helloworld

#to enter with ssh
$ docker run -it --privileged --pid=host debian nsenter -t 1  -m -u -n -i sh

#to see what is inside container
$ docker exec -it <containerId> /bin/sh

#to expose all ports use --network host especial for ephemeral ports

#Docker run command first call docker create and then docker start
#change the random host name to a specific hostname
$docker run --rm -ti --hostname=<hostNameFQD> ubuntu:latest /bin/bash

#by default the container dns is the host resolve.conf but you could override using --dns=<dnsValue> and --dns-search=<dnsSearchHost>#mac address could be override by --mad-address=<macAddress>
#### docker cli #####
# use -it every time you run an interactive commands or -d in detach mode
# use CTRL-P CTRL-Q will detach from the container use attach to go back to container
# script to use to delete all containers (use carefully if you dont't want to remove a stoped container)
$ docker container rm $(docker container ls -aq)
# use --rm it will delete the container when it is exit

####DOCKERFILE
# FROM loads an image
# WORKDIR sets up a working directory
# EXPOSE identifies a port for app to listen on
# CMD runs the app and passes parameters
# ENV set up env variable
# ADD/COPY copy files from host system
# ENTRYPOINT target a and runs a specifica application


## MICROSERVICES
# install docker on ubuntu mate
$ apt-get install docker.io
# to validate the docker installation
$ docker run hello-world



################## HEALTHCHECK in Dockerfile
$ HEALTHCHECK --interval=30s \
    --timeout=10s
    --retries=3
    --start-period=60s
    CMD curl -f http://localhost:3000/health || exit 1
# where:
# --interval define the wait time between health checks
# --timeout defines how long Docker should wait if the health check does not respond
# --start-period define the time that it takes to start the container so it could reply to the query
# the command should deliver: 1 if it sucess, 0 if it fails and timeout

#This could be set also into the stack.yml for the docker swarm

################# Mount and volumes ####################################

#to mount directory from host machine by example by default shared are rw but it could ro using ro
$ docker run --rm -ti -v <host_directory>:<mount-directory>:ro ubuntu:latest /bin/bash

#option to shared between containter is z for private is Z like : <host_directory>:<mount_directory>:z
#you could mount the root directory as readonly using --read-only=true
#to mount a temporary file like /tmp the following option should be use --tmpfs/tmp:rw,noexec,nodev,nosuid,size=256M

#to create a volume to be attached to the container
$ docker volume create <name-of-volume>
#to inspect a created volume
$ docker volume inspect <name-of-volume>
#to mount a volume to a container use --mount source=<name-of-volume>,target=<target-directory>
#to delete the volume which will lost any data writed into the volume
$ docker volume rm <name-of-volume>

#Type of backends:
# Overlay and overlay2 is a union filesystem where multiple layers are mounted together so they appear as a single file system
# AuFs is the original one and is no longer recommended
# Btrfs is a copy on write filesystem, it is ok but does not support SELinux
# Device Mapper is on RedHat OS. By default is use loop-lvm mode which has zero configuration which is very slow, for production use direct-lvm
# VFS is the simplest and slowest. Is very slow to create new containers but runtime is native
# ZFS for production with increase cost due to license
# selecting storage is used by example :
$ dockerd --storage-driver=devicemapper


############################## Quota ######################################

#for the quota you could use : --cpu 2 --io 1 --vm 2 --vm-bytes 128M --timeout 120s --memory <memory_value> and also -cpu-#--memory-swap <memory value> is for both phisical memory and swap
quota also --cpus=<value between 0.01 and number of cpu>

#use --cpuset=cpu_number to set afinity to a specific hardware cpu
#to dimically update quotas you could use
$ docker update --cpus="1.5" <containerID1> ... <containerIDn>

#The telltale sign of out of memory is a container exit code of 137 and kernel out-of-memory (OOM) messages in the dmesg output.
#Docker has features that allow you to tune and disable the Linux OOM killer by using the --oom-kill-disable and the --oom-score-adj arguments to docker run.

#Block IO
#To set this weight on a container, you need to pass the --blkio-weight to your docker run command with a valid value. You can also target a specific device using the --blkio-weight-device option.

#As with CPU shares, tuning the weights is hard to get right in practice, but we can make it vastly simpler by limiting the maximum number of bytes or operations per second that are available to a container via its cgroup. The following settings let us control that:

#--device-read-bps     Limit read rate (bytes per second) from a device
#--device-read-iops    Limit read rate (IO per second) from a device
#--device-write-bps    Limit write rate (bytes per second) to a device
#--device-write-iops   Limit write rate (IO per second) to a device

#set the docker soft limit to 50 open files andhard limit to 150 open files
$ sudo dockerd --default-ulimit nofile=50:150

#to create a container use
$ docker create -p <docker_port:host:port> <imageName>
#to see all containers use
$ docker ps -a
#to start a container use
$ docker start <containerId>
#To autorestart containers use --restart:on-failure, then whenever the container exits with a nonzero exit code or --restart:unless stopped if you want to autorestart unless you specific stopped it, other options :no, always
#the --restart:<type of failure>:<nr of retries>
#stop the container send SIGTERM if you add -t <timeout> it will send SIGKILL after timeout
#on docker kill you could add the --signal=<name of the signal>

#to clean-up all dockers in dev there is the command:
$ docker system prune

#to delete all of containers on docker host use:
$ docker rm $(docker ps -a -q)

#to delete all images on docker host use:
$ docker rmmi $(docker images -q)

#Docker ps and docker images have filter capability using --filter like:
$ docker rm $(docker ps -a -q --filter 'exited!=0')
#of for untagged containers
$ docker rmi $(docker images -q -f "dangling=true")

#In most installations, /var/lib/docker will be the default root directory used to store images and containers. If you need to change this, you can edit your Docker startup scripts to launch the daemon, with the --data-root argument pointing to a new storage location. To test this by hand, you could run something like this:
$ sudo dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 --data-root="/data/docker"

#The syntax for pulling them from the registry is very similar, but note the @ in the tag.
$ docker pull ubuntu@sha256:2f9a...82cf

#Docker containers don\92t, by default, start anything in the background like a full virtual machine would. They\92re a lot lighter weight than that and therefore don\92t start an init system.

#by default docker redirect input and output to the caller of the docker

#the other equivalence of the docker exec is nsenter but this should be run on the docker server host
#first obtain the pid of the docker process
$ PID=$(docker inspect --format \{{.State.Pid\}} <containerId>)
#the run 
$ sudo nsenter --target $PID --mount --uts --ipc --net --pid
#or in one line
$ sudo nsenter --target $(docker inspect --format \{{.State.Pid\}} <containerId>) --mount --uts --ipc --net --pid /bin/sh
# wrapper from git is https://github.com/Pithikos/docker-enter


#log are stored on /var/lib/docker/containers/<container_id>/ where the <container_id> in json format
#logging rotation: The default settings do not currently enable log rotation. You\92ll want to make sure you specify the --log-opt max-size and --log-opt max-file settings if running in production. 
#to change to other type of log : he supported option that currently is the simplest for running Docker at scale is the option to send your container logs to syslog directly from Docker. You can specify this on the Docker command line with the --log-driver=syslog option or set it as the default in the daemon.json file for all containers. Then restart the daemon.

#You can log directly to a remote syslog-compatible server from a single container by setting the log option syslog-address similar to this: --log-opt syslog-address=udp://192.168.42.42:123.

#API running on docker like statistics in pretty-print format
$ curl --unix-socket /var/run/docker.sock http://v1/containers/91c86ec7b33f/stats | head -1 | python3 json.tool

#health check git location  https://github.com/spkane/rocketchat-hubot-demo.git

#docker events to monitor events on container
$ docker events
#or the equivalent
$ curl --unix-socket /var/run/docker.sock http://v1/events

#cadivisor to have charts on 8080 port of the docker container which run cadvisor or rest on 8080/api/v1.3/containers/
$ docker run --volume=/:/rootfs:ro --volume=/var/run:/var/run:rw --volume=/sys:/sys:ro --volume=/var/lib/docker/:/var/lib/docker:ro --publish=8080:8080 --detach=true --name=cadvisor google/cadvisor:latest
#for fedora or RHEL you need also the volume :  --volume=/cgroup:/cgroup \.

#In Dockerfile the COPY will copy the host file into container the ADD will get from network or untar the tar
#on ADD you could said what type of security --chown=UID:GID
#WORKDIR change the context of layers is not equivalent with RUN cd because the last one is not persisted
#Put on the first part of the Dockerfile the part that is not change every time so those layers will not be rebuild each time.
#use .dockerignore which is like .gitignore to filter the files which will be put pattern to exclude files from the directory.
#docker image save and load should be use to create a tarball from an image and recreate the image from the tarball.

#Image name: <registry URL>/<User or Org>/<name>:<tag>
#<registry URL> the default is docker.io but thare are more like :
# https://cloud.google.com/container-registry
# https://aws.amazon.com/ecr/
# https://azure.microsoft.com/en-us/services/container-registry/
# https://access.redhat.com/container/
# https://jfrog.com/integration/artifactory-docker-registry

# docker inspect could use --format to filter the result

########################NETWORK ###############################################
# Bridge is provided by docker and is local. Simple network based on Linux bridgs allowing networking on a single host
# Macvlan is provided by docker and is local. Configures multiple layer 2 (MAC) addresses on a single physical host interface. When migrating legacy system to a container-native one, this can be a really useful step.
# Overlay is provided by docker and is global. Multinode-capable container network based on Virtual Extensible LAN (VXLan) is used by docker swarm
# Weave Net is provided by Weaveworks and is global. Simple, resilient, multihost Docker networking.
# Contiv Network Plugin is provided by Cisco and is global . Open Source container networking.

#To list network on host use:
$ docker network ls

#To specify the network range (subnet) when creating a new network you should use like this:
$ docker network create --driver bridge --subnet "10.1.0.0/16" test-net

#Host network should never be used in production is the same network for the container as the host (like the same ip)
#you could ask the running container to run in the same network as another container specifing  --network container:<containerName>
#to expose port use -p <host port>:<container port>/<protocol like tcp/udp> the tcp is the default protocol
$ docker network inspect <network_id>
# on -p (--publish) you could specify the ip address
# to publish port the application should listen on eth0 address
# to publish multiple ports use -p multiple port or specify a range
# the link will put ip address host name into the /etc/hosts but only at start-up (the link is deprecated)
# use docker network inspect to see the ip range of the network
# when a container is started the container name is put into the dns if the user network is used
# link could have aliases --link <container_name>:<alias>
# same name on multiple container in the same network use --network-alias (especial for loadbalancer purpose)

############################## DOCKER SECURITY ####################################################

#run the container in privileged mode so it you want to add device mount etc : add at container start --privileged=true
#The container could be run with non privileged user using -u <userId> otherwise is root
#all containers could be run with non priviledged user using --serns-remap in dockerd command
#if in priviledged container you mount swap using swapon <swap file> be sure you do swapoff before exit the container otherwise the container couln't be destroy
#if you forget that you could unmount from host using root like:
$ sudo swapoff /var/lib/docker/overlay/<containerId>/upper/<swap_file>
#if you want only some priviledged use --cap-add=<priviledge> and if you want to disable some priviledge you use --cap-drop=<priviledge>
#you could use  seccomp profile file to fine grain the capability of the container
#use -tlsverify to require certificates if you are in production

############################### DOCKER ARCHITECTURE #################################################

# dockerd - one per server, build container images, management : high level network, volumes, logging, statistics etc
# containerd - one per server, manages lifecycle execution, copy on write fileisystem an low level network
# docker-containerd-shim - one per container, handle IO and reports exit status
# runc - constructs the container and execution, statistics, reports events on lifecycle
#runtime continer could be Clear Containers (cc-runtime), runc or Railcar to select one use
$ docker run --runtime <runtime> -d <command>
#to see which container works with by example use :
$ sudo cc-runtime list
#gVisor is for high secure isolation and for for massive scalling, the runtime is runsc

############################### OTHER STUFF #######################################################

#If you use a process manager or initialization system on your servers, like upstart or systemd, it is usually very easy to direct all process output to STDOUT and STDERR and then have your process monitor capture them and send them to a remote logging host.
# progrim for loadbalancer
# infrastructure teraform

buildah.io or with ADD file ../
user ARG to pass arguments

